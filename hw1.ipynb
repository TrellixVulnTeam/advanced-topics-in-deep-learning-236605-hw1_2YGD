{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.datasets.utils import download_url\n",
    "import os\n",
    "import tarfile\n",
    "import hashlib\n",
    "\n",
    "# https://github.com/fastai/imagenette\n",
    "dataset_url = 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz'\n",
    "dataset_filename = dataset_url.split('/')[-1]\n",
    "dataset_foldername = dataset_filename.split('.')[0]\n",
    "data_path = './data'\n",
    "dataset_filepath = os.path.join(data_path,dataset_filename)\n",
    "dataset_folderpath = os.path.join(data_path,dataset_foldername)\n",
    "\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "download = False\n",
    "if not os.path.exists(dataset_filepath):\n",
    "    download = True\n",
    "else:\n",
    "    md5_hash = hashlib.md5()\n",
    "\n",
    "\n",
    "    file = open(dataset_filepath, \"rb\")\n",
    "\n",
    "    content = file.read()\n",
    "\n",
    "    md5_hash.update(content)\n",
    "\n",
    "\n",
    "    digest = md5_hash.hexdigest()\n",
    "    if digest != 'fe2fc210e6bb7c5664d602c3cd71e612':\n",
    "        download = True\n",
    "if download:\n",
    "    download_url(dataset_url, data_path)\n",
    "\n",
    "with tarfile.open(dataset_filepath, 'r:gz') as tar:\n",
    "    tar.extractall(path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoCropsTransform:\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform):\n",
    "        self.base_transform = base_transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        q = self.base_transform(x)\n",
    "        k = self.base_transform(x)\n",
    "        return [q, k]\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '(\\n\\t'\n",
    "        format_string += self.base_transform.__repr__().replace('\\n', '\\n\\t')\n",
    "        format_string += '\\n)'\n",
    "        return format_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "size  = 224\n",
    "ks = (int(0.1 * size) // 2) * 2 + 1 # should be odd\n",
    "__imagenet_stats = {'mean': [0.485, 0.456, 0.406],\n",
    "                    'std': [0.229, 0.224, 0.225]}\n",
    "\n",
    "train_transform = TwoCropsTransform(transforms.Compose([transforms.RandomResizedCrop(scale=(0.2, 1), size=size),\n",
    "                                      # transforms.RandomHorizontalFlip(),\n",
    "                                      # transforms.RandomApply([transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)], p=0.8),\n",
    "                                      # transforms.RandomGrayscale(p=0.2),\n",
    "                                    #   transforms.GaussianBlur(kernel_size=ks),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(**__imagenet_stats)]))\n",
    "\n",
    "dataset_train = torchvision.datasets.ImageFolder(os.path.join(dataset_folderpath,'train'), train_transform)\n",
    "#valid_ds = ImageFolder('./data/imagenette-160/val', valid_tfms)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=8,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_numpy_samples(inputs):\n",
    "        mean = torch.as_tensor(__imagenet_stats['mean'], dtype=inputs.dtype, device=inputs.device)\n",
    "        std = torch.as_tensor(__imagenet_stats['std'], dtype=inputs.dtype, device=inputs.device)\n",
    "        inputs = inputs * std.view(1, -1, 1, 1) + mean.view(1, -1, 1, 1)\n",
    "        inputs = inputs.numpy()\n",
    "        inputs = np.transpose(inputs, (0,2,3,1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "     \n",
    "fig, axes = plt.subplots(nrows=batch_size, ncols=2, figsize=(10,100))\n",
    "for (input1, input2), _ in train_dataloader:\n",
    "    np_inputs1, np_inputs2 = get_numpy_samples(input1), get_numpy_samples(input2)\n",
    "    for row in range(batch_size):\n",
    "        axes[row, 0].axis(\"off\")\n",
    "        axes[row, 0].imshow(np_inputs1[row])\n",
    "        axes[row, 1].axis(\"off\")\n",
    "        axes[row, 1].imshow(np_inputs2[row])\n",
    "    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}